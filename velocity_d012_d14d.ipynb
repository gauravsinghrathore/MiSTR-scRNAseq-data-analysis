{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"MKL_NUM_THREADS\"] = \"50\"\n",
    "#os.environ[\"NUMEXPR_NUM_THREADS\"] = \"50\"\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"50\"\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "\n",
    "import loompy\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy.sparse\n",
    "import bbknn\n",
    "import scanpy.external as sce\n",
    "from gprofiler import GProfiler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "sc.set_figure_params(dpi = 150, dpi_save = 300, format = 'png')\n",
    "sc._settings.ScanpyConfig(verbosity=0)\n",
    "\n",
    "#############################################################################\n",
    "# COMPILE COMMAND LINE ######################################################\n",
    "#jupyter nbconvert --ExecutePreprocessor.timeout=80000 --execute --to html\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET CONSTANSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the loom files need to be merged prior to anything?\n",
    "Need_to_combine = False\n",
    "if Need_to_combine:\n",
    "    Experiment_names = [] #LIST HERE YOUR EXPERIMENT NAMES e.g. \"d0es\",\"d1d\",etc.. as they appear in the loom file name\n",
    "    FILE_DIR = \"\"# LOCATION OF YOUR LOOM FILES\n",
    "\n",
    "OUTPUT_FILE_DIR = \"/scratch/gaurav/loom-files\" # THE DIRECTORY YOUR COMBINED LOOM FILE IS IN\n",
    "loompy_output = \"d0-1-2-14.loom\" # YOUR COMBINED LOOM FILE NAME\n",
    "\n",
    "# PROVIDE CELL CYCLE GENE LISTS FOR PHASE SCORING\n",
    "S_genes_file = \"~/s_genes.csv\"\n",
    "G2M_genes_file = \"~/g2m_genes.csv\"\n",
    "S_phase_genes = pd.read_csv(S_genes_file)[\"x\"].to_list()\n",
    "G2M_phase_genes = pd.read_csv(S_genes_file)[\"x\"].to_list()\n",
    "\n",
    "# HERE YOU CAN CHOOSE A FEW HYPERPARAMETERS FOR YOUR ANALYSIS\n",
    "BBKNN_neighbors = 5\n",
    "ClusteringResolution = 0.5\n",
    "\n",
    "gp = GProfiler(return_dataframe=True)\n",
    "ExportEmbeddingClusteringInfo = True # WHETHER TO EXPORT THE EMBEDDING AND CLUSTERING INFO YOU WILL COMPUTE FOR EXTERNAL ANALYSES (e.g. Monocle etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############DEFINE FUNCTIONS########\n",
    "def Add_obs(loaded_obj):\n",
    "    mito_genes = loaded_obj.var_names.str.startswith(('MT-', 'MTRNR'))\n",
    "    ribo_genes = loaded_obj.var_names.str.startswith(('RPL','RPS')) #, 'RP[0-5][0-9]'))\n",
    "    loaded_obj.obs['percent_mito'] = np.sum(loaded_obj[:, mito_genes].X, \n",
    "                                            axis=1).A1 / np.sum(loaded_obj.X, axis=1).A1\n",
    "    loaded_obj.obs['percent_ribo'] = np.sum(loaded_obj[:, ribo_genes].X, \n",
    "                                            axis=1).A1 / np.sum(loaded_obj.X, axis=1).A1\n",
    "    loaded_obj.obs['n_counts'] = loaded_obj.X.sum(axis=1).A1\n",
    "    loaded_obj.obs[\"SampleID\"] = [\"d2d\" if ID[0] == \"48hrsd\" else \n",
    "                                  \"d14d-1\" if ID[0] == \"d14dc\" else \n",
    "                                  \"d14d-2\" if ID[0] == \"d14-d-d\" else \n",
    "                                  \"d14d-3\" if ID[0] == \"d14-d-e\" else \n",
    "                                  ID[0] for ID in loaded_obj.obs_names.str.split(\"-5\")]\n",
    "    \n",
    "    return(loaded_obj)\n",
    "\n",
    "def Get_genes_to_keep(loaded_obj):\n",
    "    detected_genes = loaded_obj[:,sc.pp.filter_genes(loaded_obj, min_cells=3, \n",
    "                                                     inplace=False)[0]].var_names.tolist()\n",
    "    MitoRiboGenes = (list(filter(lambda x: re.search(r'^MT-', x, re.IGNORECASE), detected_genes)) + \n",
    "                     list(filter(lambda x: re.search(r'^MTRNR', x, re.IGNORECASE), detected_genes)) + \n",
    "                     list(filter(lambda x: re.search(r'^RPL', x, re.IGNORECASE), detected_genes)) +\n",
    "                     # \"^RP[0-5][0-9]\" catches a lot of non ribosomal proteins like LINCs, Pseudogenes and even prot coding genes\n",
    "                     #list(filter(lambda x: re.search(r'^RP[0-5][0-9]', x, re.IGNORECASE), detected_genes)) +\n",
    "                     list(filter(lambda x: re.search(r'^RPS', x, re.IGNORECASE), detected_genes)))\n",
    "    return(list(set(detected_genes) - set(MitoRiboGenes)))\n",
    "\n",
    "def plot_pca_loadings_customized(adata, n_genes, n_comp):\n",
    "    ind = np.argsort(adata.varm['PCs'][:,0:n_comp], axis=0)[-n_genes:][::-1] # get indeces of top 20 genes in top 5 PCs\n",
    "    plotting_df = pd.DataFrame(columns=['Gene','PC_importance', 'Component'])\n",
    "    for n in range(n_comp):\n",
    "        component_number = n + 1\n",
    "        plotting_df = pd.concat([plotting_df,\n",
    "                    pd.DataFrame(np.vstack((adata.var.iloc[ind[:,n]].index, \n",
    "                                            adata.varm['PCs'][ind[:,n],n], \n",
    "                                            [\"PC {}\".format(component_number)]*n_genes)).T, \n",
    "                                 columns=['Gene','PC_importance', 'Component'])])\n",
    "\n",
    "    g = sns.FacetGrid(plotting_df, col=\"Component\", sharey=False, height=5)\n",
    "    g = g.map(plt.scatter, \"PC_importance\", \"Gene\", edgecolor=\"w\")\n",
    "\n",
    "def PCA_plotting_wrapper(loaded_obj):\n",
    "    sc.pl.pca_variance_ratio(loaded_obj, log=True)\n",
    "    plot_pca_loadings_customized(loaded_obj, 20, 5)\n",
    "    sc.pl.pca(loaded_obj, color = ['SampleID'], legend_loc = 'on data', use_raw = False, \n",
    "              components = ['1,2', '2,3', '3,4'], ncols = 3, wspace = 0, \n",
    "              title = [\"PC1 vs PC2\", \"PC2 vs PC3\", \"PC3 vs PC4\"])\n",
    "    \n",
    "def PreProcessing(obj, QCplots=False, Verbosity=\"high\"):\n",
    "    obj = Add_obs(obj)\n",
    "  \n",
    "    if QCplots:\n",
    "        sc.pl.violin(obj, ['percent_mito', 'percent_ribo', 'n_counts'], jitter=0.4, multi_panel=True)\n",
    "\n",
    "    # first round of gene filtering\n",
    "    Genes_to_keep = Get_genes_to_keep(obj)\n",
    "    obj = obj[:,Genes_to_keep]\n",
    "    if Verbosity==\"high\":\n",
    "        print(\"First gene filtering: \"+str(obj.X.shape))\n",
    "\n",
    "    # Cells filtering\n",
    "    sc.pp.filter_cells(obj, min_genes=200)\n",
    "    median_genes_per_cell = np.median(obj.X.getnnz(axis=1)) # recomputing this per each dataset will introduce inconsistent thrholds\n",
    "    sc.pp.filter_cells(obj, max_genes=2.5*median_genes_per_cell)\n",
    "    if Verbosity==\"high\":\n",
    "        print(\"Cell filtering: \"+str(obj.X.shape))\n",
    "\n",
    "    # Second round of gene filtering: some genes got to all-zeros after cell filtering\n",
    "    Genes_to_keep_2 = Get_genes_to_keep(obj)\n",
    "    obj = obj[:,Genes_to_keep_2]\n",
    "    if Verbosity==\"high\":\n",
    "        print(\"Second gene filtering: \"+str(obj.X.shape))\n",
    "\n",
    "    obj = Add_obs(obj)\n",
    "    if QCplots:\n",
    "        sc.pl.violin(obj, ['percent_mito', 'percent_ribo', \n",
    "                           'n_counts', 'n_genes'], jitter=0.4, multi_panel=True)\n",
    "\n",
    "    if Verbosity==\"high\":\n",
    "        print(\"Raw!\")\n",
    "        print(obj.X[:10,:10])\n",
    "\n",
    "    sc.pp.normalize_total(obj, layers=\"all\")\n",
    "    if Verbosity==\"high\":\n",
    "        print(\"Normalized\")\n",
    "        print(obj.X[:10,:10])\n",
    "\n",
    "    sc.pp.log1p(obj)\n",
    "    if Verbosity==\"high\":\n",
    "        print(\"Log transformed\")\n",
    "        print(obj.X[:10,:10])\n",
    "\n",
    "    sc.pp.highly_variable_genes(obj, subset=True) # needs log transformed data\n",
    "    if QCplots:\n",
    "        sc.pl.highly_variable_genes(obj)\n",
    "    if Verbosity==\"high\":\n",
    "        print(\"HVG subset: \"+str(obj.shape))\n",
    "    \n",
    "    return(obj)\n",
    "\n",
    "def CellCycleRegression(obj, CCregr):\n",
    "    \n",
    "    # N.B. Regression is only performed on matrix .X\n",
    "    if CCregr == \"IndPhase\":\n",
    "        print(\"Regressing individual phases\")\n",
    "        sc.pp.scale(obj)\n",
    "        sc.tl.score_genes_cell_cycle(obj, s_genes=S_phase_genes, g2m_genes=G2M_phase_genes)\n",
    "        sc.pp.regress_out(obj, ['S_score', 'G2M_score'])\n",
    "        sc.pp.scale(obj)\n",
    "        # Store \"old_phase\" for later plotting of regression effect on phase%\n",
    "        obj.obs['OldPhase'] = obj.obs['phase']\n",
    "        sc.tl.score_genes_cell_cycle(obj, s_genes=S_phase_genes, g2m_genes=G2M_phase_genes)\n",
    "        print(\"Regressed\")\n",
    "        print(obj.X[:10,:10])\n",
    "    elif CCregr == \"PhaseDiff\":\n",
    "        print(\"Regressing phases difference\")\n",
    "        sc.pp.scale(obj)\n",
    "        sc.tl.score_genes_cell_cycle(obj, s_genes=S_phase_genes, g2m_genes=G2M_phase_genes)\n",
    "        obj.obs[\"CC_Difference\"] = obj.obs[\"S_score\"] - obj.obs[\"G2M_score\"]\n",
    "        sc.pp.regress_out(obj, [\"CC_Difference\"])\n",
    "        sc.pp.scale(obj)\n",
    "        obj.obs['OldPhase'] = obj.obs['phase']\n",
    "        sc.tl.score_genes_cell_cycle(obj, s_genes=S_phase_genes, g2m_genes=G2M_phase_genes)\n",
    "        print(\"Regressed\")\n",
    "        print(obj.X[:10,:10])\n",
    "    elif CCregr == None:\n",
    "        print(\"No regression performed\")\n",
    "        sc.pp.scale(obj)\n",
    "        sc.tl.score_genes_cell_cycle(obj, s_genes=S_phase_genes, g2m_genes=G2M_phase_genes)\n",
    "    \n",
    "    return(obj)\n",
    "\n",
    "def ClusteringOperations(obj, \n",
    "                         ExportTables2csv, \n",
    "                         plotTopMarkersHeatmap=False, \n",
    "                         DisplayTables=False, \n",
    "                         csv_suffix=None, \n",
    "                         GO_enrichment=True, \n",
    "                         PlotCycleTermsProportions=True):\n",
    "    \n",
    "    sc.tl.louvain(obj, flavor='vtraag', directed=True,\n",
    "                  use_weights=True, resolution = ClusteringResolution)\n",
    "    sc.tl.rank_genes_groups(obj, groupby = 'louvain', use_raw = False)\n",
    "    if plotTopMarkersHeatmap:\n",
    "        sc.pl.rank_genes_groups_matrixplot(obj)\n",
    "    TopMarkersTable = pd.DataFrame(obj.uns['rank_genes_groups']['names'][0:20])\n",
    "    if DisplayTables:\n",
    "        print(TopMarkersTable)\n",
    "    if ExportTables2csv:\n",
    "        TopMarkersTable.to_csv(\"TopMarkers_\"+csv_suffix+\".csv\")\n",
    "\n",
    "    if GO_enrichment:\n",
    "        df_zero = pd.DataFrame()\n",
    "        for cluster_number in range(len(\n",
    "            pd.DataFrame(obj.uns['rank_genes_groups']['names'][0:20]).columns)):\n",
    "            df = gp.profile(organism='hsapiens',\n",
    "                            query=list(\n",
    "                                pd.DataFrame(\n",
    "                                    obj.uns['rank_genes_groups'][\n",
    "                                        'names'][0:20]).iloc[\n",
    "                                    :,cluster_number])).iloc[:10,:].loc[:,[\"native\",\n",
    "                                                                           \"name\",\n",
    "                                                                           \"p_value\",\n",
    "                                                                           \"term_size\",\n",
    "                                                                           \"query_size\",\n",
    "                                                                           \"intersection_size\"]]\n",
    "            df['Cluster'] = [cluster_number]*df.shape[0]\n",
    "            df_zero = pd.concat([df_zero, df])\n",
    "            \n",
    "        if PlotCycleTermsProportions:\n",
    "            CycleTerms = pd.DataFrame(df_zero.name.str.contains(\n",
    "                \"cycle|mitotic|chromosom|nuclear|chromatid|M |phase|division|G1/S\", \n",
    "                case=False).groupby(df_zero[\"Cluster\"]).sum())\n",
    "            CycleTerms['Terms'] = [\"CycleTerms\"]*len(CycleTerms)\n",
    "            TotTerms = pd.DataFrame(df_zero.name.groupby(df_zero[\"Cluster\"]).count())\n",
    "            TotTerms['Terms'] = [\"TotTerms\"]*len(TotTerms)\n",
    "            df = pd.DataFrame(pd.concat([CycleTerms, TotTerms], axis=0))\n",
    "            df.reset_index(inplace=True)\n",
    "            df.columns = [\"Cluster\",\"Count\", \"Terms\"]\n",
    "            df['Cluster'] = df['Cluster'].astype(int)\n",
    "            df['Count'] = df['Count'].astype(int)\n",
    "            sns.set(font_scale = 0.9)\n",
    "            sns.catplot(data=df, x=\"Cluster\", y=\"Count\", hue=\"Terms\", kind=\"bar\")\n",
    "            \n",
    "        if DisplayTables:\n",
    "            print(df_zero)\n",
    "            \n",
    "        if ExportTables2csv:\n",
    "            df_zero.to_csv(\"GOterms_\"+csv_suffix+\".csv\")\n",
    "            \n",
    "    return(obj)\n",
    "            \n",
    "def DimensionalityReduction_and_Clustering(obj, \n",
    "                                           PCAplots=False, \n",
    "                                           DataSetIntegration=None, \n",
    "                                           CCregr=None,\n",
    "                                           ClusteringTopGenesHeatmap=False,\n",
    "                                           DisplayClusteringTables=False, \n",
    "                                           ExportClusteringTables=False, \n",
    "                                           analysed_timepoint=\"FullData\",\n",
    "                                           GOterm=False): \n",
    "    # DataSetIntegration is one of  / \"MNN\" / \n",
    "    # CCregr is one of \"IndPhase\" /\n",
    "    # analysed_timepoint is one of \"FullData\" (default) / \"d012\" / \"d14\". It needs to be provided if ExportClusteringTables == True\n",
    "    \n",
    "    num_PCs = 15\n",
    "\n",
    "        \n",
    "    if DataSetIntegration == \"MNN\":\n",
    "        \n",
    "        print(\"Performing MNN\")\n",
    "        Datasets_list = []\n",
    "        for ID in np.unique(obj.obs[\"SampleID\"]):\n",
    "            Datasets_list.append(obj[np.where(obj.obs.loc[:,\"SampleID\"] == ID)[0],:])\n",
    "        if analysed_timepoint == \"d14\": # in case of day 14\n",
    "            obj = sce.pp.mnn_correct(Datasets_list[0], \n",
    "                                     Datasets_list[1], \n",
    "                                     Datasets_list[2], batch_key = \"SampleID\")[0]\n",
    "        elif analysed_timepoint == \"d012\": # for day 0, 1, 2\n",
    "            obj = sce.pp.mnn_correct(Datasets_list[0], \n",
    "                                     Datasets_list[1], \n",
    "                                     Datasets_list[2], \n",
    "                                     Datasets_list[3], \n",
    "                                     Datasets_list[4], batch_key = \"SampleID\")[0]\n",
    "        elif analysed_timepoint == \"FullData\": # for day 0, 1, 2\n",
    "            obj = sce.pp.mnn_correct(Datasets_list[0], \n",
    "                                     Datasets_list[4], \n",
    "                                     Datasets_list[5], \n",
    "                                     Datasets_list[6], \n",
    "                                     Datasets_list[7],\n",
    "                                     Datasets_list[1], \n",
    "                                     Datasets_list[2], \n",
    "                                     Datasets_list[3], batch_key = \"SampleID\")[0] #,mnn_order=['d0es', 'd1d', 'd1v', 'd2d', 'd2v', 'd14d-1', 'd14d-2', 'd14d-3']\n",
    "        obj.obs_names = [x[:-2] for x in obj.obs_names] # remove the suffix MNN put to obs_names as it messess with the exporting later\n",
    "        \n",
    "        obj = CellCycleRegression(obj, CCregr)\n",
    "        print(\"Performing PCA\")\n",
    "        sc.tl.pca(obj, n_comps=50, zero_center=None, svd_solver='auto', use_highly_variable=None) # hvg only if there\n",
    "        if PCAplots:\n",
    "            PCA_plotting_wrapper(obj)\n",
    "            sc.pl.pca(obj, color = ['OTX2', 'GBX2'], legend_loc = 'on data', use_raw = False)\n",
    "        sc.pp.scale(obj)\n",
    "        print(\"Computing knn\")\n",
    "        sc.pp.neighbors(obj, n_neighbors=30, n_pcs=num_PCs, method='umap', use_rep = 'X_pca')\n",
    "\n",
    "    obj = ClusteringOperations(obj, \n",
    "                               plotTopMarkersHeatmap = ClusteringTopGenesHeatmap,\n",
    "                               DisplayTables = DisplayClusteringTables, \n",
    "                               ExportTables2csv = ExportClusteringTables, \n",
    "                               csv_suffix = str(\n",
    "                                   analysed_timepoint)+\"_\"+str(DataSetIntegration)+\"_\"+str(CCregr), \n",
    "                               GO_enrichment = GOterm,\n",
    "                               PlotCycleTermsProportions = GOterm)\n",
    "    sc.tl.umap(obj, spread=1.0, min_dist=0.5)\n",
    "    \n",
    "    return(obj)\n",
    "\n",
    "def Export_UMAP_clustering(obj, ExportEmbeddingClusteringInfo_suffix):\n",
    "    \n",
    "    np.savetxt(\"ScanpyObsNames_\"+ExportEmbeddingClusteringInfo_suffix+\".txt\",\n",
    "               np.array(obj.obs_names), delimiter=\",\", fmt='%s')\n",
    "    np.savetxt(\"ScanpyLouvainClustering_\"+ExportEmbeddingClusteringInfo_suffix+\".txt\",\n",
    "               obj.obs.loc[:,'louvain'].reset_index(), delimiter=\",\", fmt='%s')\n",
    "    np.savetxt(\"ScanpyUMAPCoord_\"+ExportEmbeddingClusteringInfo_suffix+\".txt\",\n",
    "               obj.obsm['X_umap'], delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########COMBINE INPUT LOOM FILES IF REQUIRED, THEN READ########\n",
    "\n",
    "\n",
    "if Need_to_combine:\n",
    "    loompy.combine([FILE_DIR+\"/\"+name+\"-5000_cells.loom\" for name in Experiment_names], \n",
    "                   OUTPUT_FILE_DIR+\"/\"+loompy_output,\n",
    "                   key=\"Accession\")\n",
    "    \n",
    "Scanpy_object = sc.read_loom(OUTPUT_FILE_DIR+\"/\"+loompy_output, sparse=True, cleanup=False, X_name=\"matrix\")\n",
    "while not Scanpy_object.var_names[Scanpy_object.var_names.duplicated()].empty:\n",
    "    print(\"Variables names not unique yet\")\n",
    "    Scanpy_object.var_names_make_unique()\n",
    "print(\"Variables names now unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-PROCESSING\n",
    "FullDataset = Scanpy_object.copy()\n",
    "\n",
    "FullDataset = PreProcessing(FullDataset, QCplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FULL DATA: Nothing | BBKNN | MNN | BBKNN Ind | MNN Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Embedding_clustering_wrapper_Full(Arguments): \n",
    "    \n",
    "    Full_obj = FullDataset.copy()\n",
    "    Full_obj = DimensionalityReduction_and_Clustering(Full_obj, \n",
    "                                                             PCAplots=False, \n",
    "                                                             DataSetIntegration=Arguments[0], \n",
    "                                                             CCregr=Arguments[1],\n",
    "                                                             ClusteringTopGenesHeatmap=False,\n",
    "                                                             DisplayClusteringTables = False, \n",
    "                                                             ExportClusteringTables=False, \n",
    "                                                             analysed_timepoint=\"FullData\",\n",
    "                                                             GOterm=True)\n",
    "    Full_obj.obs[\"SampleID\"] = FullDataset.obs[\"SampleID\"]\n",
    "    \n",
    "    return(Full_obj)\n",
    "\n",
    "Integration_Regression_full = [(\"MNN\", \"IndPhase\")]\n",
    "Full_list = [*map(Embedding_clustering_wrapper_Full, Integration_Regression_full)]\n",
    "\n",
    "PlotTitleList_full = [ \"Full data, MNN, IndPhase\"]\n",
    "\n",
    "for i in range(len(Full_list)):\n",
    "    sc.pl.umap(Full_list[i], color='louvain', legend_loc='on data', use_raw=False)\n",
    "    sc.pl.umap(Full_list[i], color = ['SampleID', 'OTX2', 'GBX2', 'PAX6', 'FGF17','DCX', 'phase'], \n",
    "               title = [PlotTitleList_full[i], 'OTX2', 'GBX2', 'PAX6', 'FGF17','DCX', 'phase'], \n",
    "               legend_loc = 'right margin', use_raw = False, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################SEPARATE THE DATASETS and preprocess#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scanpy_object = Add_obs(Scanpy_object)\n",
    "\n",
    "d012 = Scanpy_object[np.where(Scanpy_object.obs.loc[:,\"SampleID\"].isin([\"d0es\",\"d1d\",\"d1v\",\"d2d\",\"d2v\"]))[0],:]\n",
    "d14 = Scanpy_object[np.where(Scanpy_object.obs.loc[:,\"SampleID\"].isin([\"d14d-1\",\"d14d-2\",\"d14d-3\"]))[0],:]\n",
    "\n",
    "d012 = PreProcessing(d012, QCplots=True)\n",
    "d14 = PreProcessing(d14, QCplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################DAY 0,1,2: BBKNN | MNN | BBKNN Ind | MNN Ind | BBKNN Diff | MNN Diff###########\n",
    "def Embedding_clustering_wrapper_d012(Arguments): \n",
    "    \n",
    "    d012_obj = d012.copy()\n",
    "    d012_obj = DimensionalityReduction_and_Clustering(d012_obj, \n",
    "                                                             PCAplots=False, \n",
    "                                                             DataSetIntegration=Arguments[0], \n",
    "                                                             CCregr=Arguments[1],\n",
    "                                                             ClusteringTopGenesHeatmap=False,\n",
    "                                                             DisplayClusteringTables = False, \n",
    "                                                             ExportClusteringTables=True, \n",
    "                                                             analysed_timepoint=\"d012\",\n",
    "                                                             GOterm=True)\n",
    "    d012_obj.obs[\"SampleID\"] = d012.obs[\"SampleID\"]\n",
    "    \n",
    "    return(d012_obj)\n",
    "\n",
    "#Integration_Regression_d012 = [(\"BBKNN\", None), (\"MNN\", None), (\"BBKNN\", \"IndPhase\"), (\"MNN\", \"IndPhase\"), (\"BBKNN\", \"PhaseDiff\"), (\"MNN\", \"PhaseDiff\")]\n",
    "Integration_Regression_d012 = [ (\"MNN\", \"IndPhase\")]\n",
    "d012_list = [*map(Embedding_clustering_wrapper_d012, Integration_Regression_d012)]\n",
    "\n",
    "\n",
    "#PlotTitleList_d012 = [\"Day 0,1,2, BBKNN\", \"Day 0,1,2, MNN\", \"Day 0,1,2, BBKNN, IndPhase\", \"Day 0,1,2, MNN, IndPhase\", \"Day 0,1,2, BBKNN, PhaseDiff\", \"Day 0,1,2, MNN, PhaseDiff\"]\n",
    "PlotTitleList_d012 = [ \"Day 0,1,2, MNN, IndPhase\"]\n",
    "for i in range(len(d012_list)):\n",
    "    sc.pl.umap(d012_list[i], color='louvain', legend_loc='on data', use_raw=False)\n",
    "    #sc.pl.umap(d012_list[i], color = ['SampleID', 'OTX2', 'GBX2', 'phase'], \n",
    "    sc.pl.umap(d012_list[i], color = [ 'OTX2', 'GBX2'], \n",
    "               title = [PlotTitleList_d012[i], 'OTX2', 'GBX2', 'phase'], \n",
    "               legend_loc = 'right margin', use_raw = False, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############AY 14: BBKNN | MNN | BBKNN Ind | MNN Ind | BBKNN Diff | MNN Diff############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Embedding_clustering_wrapper_d14(Arguments): \n",
    "    \n",
    "    d14_obj = d14.copy()\n",
    "    d14_obj = DimensionalityReduction_and_Clustering(d14_obj, \n",
    "                                                             PCAplots=False, \n",
    "                                                             DataSetIntegration=Arguments[0], \n",
    "                                                             CCregr=Arguments[1],\n",
    "                                                             ClusteringTopGenesHeatmap=False,\n",
    "                                                             DisplayClusteringTables = False, \n",
    "                                                             ExportClusteringTables=True, \n",
    "                                                             analysed_timepoint=\"d14\",\n",
    "                                                             GOterm=True)\n",
    "    d14_obj.obs[\"SampleID\"] = d14.obs[\"SampleID\"]\n",
    "    \n",
    "    return(d14_obj)\n",
    "\n",
    "#Integration_Regression_d14 = [(\"BBKNN\", None), (\"MNN\", None), (\"BBKNN\", \"IndPhase\"), (\"MNN\", \"IndPhase\"), (\"BBKNN\", \"PhaseDiff\"), (\"MNN\", \"PhaseDiff\")]\n",
    "Integration_Regression_d14 = [(\"MNN\", \"IndPhase\")]\n",
    "d14_list = [*map(Embedding_clustering_wrapper_d14, Integration_Regression_d14)]\n",
    "\n",
    "#PlotTitleList_d14 = [\"Day 14, BBKNN\", \"Day 14, MNN\", \"Day 14, BBKNN, IndPhase\", \"Day 14, MNN, IndPhase\", \"Day 14, BBKNN, PhaseDiff\", \"Day 14, MNN, PhaseDiff\"]\n",
    "PlotTitleList_d14 = [ \"Day 14, MNN, IndPhase\"]\n",
    "for i in range(len(d14_list)):\n",
    "    sc.pl.umap(d14_list[i], color='louvain', legend_loc='on data', use_raw=False)\n",
    "    sc.pl.umap(d14_list[i], color = ['SampleID', 'OTX2', 'GBX2', 'PAX6', 'FGF17','DCX', 'phase'], \n",
    "               title = [PlotTitleList_d14[i], 'OTX2', 'GBX2', 'PAX6', 'FGF17','DCX', 'phase'], \n",
    "               legend_loc = 'right margin', use_raw = False, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######EXPORT UMAP AND CLUSTERING INFORMATION FOR EXTERNAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_list = [ \"d012_MNN_IndRegr\"]\n",
    "for n in range(len(suffix_list)):\n",
    "    Export_UMAP_clustering(d012_list[i], suffix_list[n])\n",
    "    \n",
    "#suffix_list = [ \"d14_MNN_IndRegr\"]\n",
    "#for n in range(len(suffix_list)):\n",
    "#    Export_UMAP_clustering(d14_list[i], suffix_list[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################FROM HERE ON IS VELOCITY##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvelo as scv\n",
    "scv.settings.verbosity = 3  # show errors(0), warnings(1), info(2), hints(3)\n",
    "scv.settings.set_figure_params('scvelo')\n",
    "scv.logging.print_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset_loading_and_cleanup(dataset):\n",
    "    # dataset is one of \"FullDataset\" | \"d012\" | \"d14\"\n",
    "    \n",
    "    FullDataset = Scanpy_object.copy()\n",
    "    FullDataset = Add_obs(FullDataset)\n",
    "    \n",
    "    if dataset == \"d012\":\n",
    "        adata = FullDataset[np.where(FullDataset.obs.loc[:,\"SampleID\"].isin([\"d0es\",\"d1d\",\"d1v\",\"d2d\",\"d2v\"]))[0],:]\n",
    "    elif dataset == \"d14\":\n",
    "        adata = FullDataset[np.where(FullDataset.obs.loc[:,\"SampleID\"].isin([\"d14d-1\",\"d14d-2\",\"d14d-3\"]))[0],:]\n",
    "    elif dataset == \"FullDataset\":\n",
    "        adata = FullDataset.copy()\n",
    "    del(FullDataset)\n",
    "    \n",
    "    print(\"Cleaning \"+str(dataset))\n",
    "    scv.utils.cleanup(adata)\n",
    "    #scv.utils.clean_obs_names(adata)\n",
    "    while not adata.var_names[adata.var_names.duplicated()].empty:\n",
    "        print(\"Variables names not unique yet\")\n",
    "        adata.var_names_make_unique()\n",
    "    print(\"Variables names now unique\")\n",
    "    print(adata)\n",
    "    scv.utils.show_proportions(adata)\n",
    "    \n",
    "    return(adata)\n",
    "\n",
    "def Velocity_PreProcessing_UMAP_Clustering(obj, Scanpy_obj):\n",
    "    # UMAP and Clustering information is passed from one of the objects processed above,\n",
    "    # to be indicated with the Scanpy_obj argument\n",
    "    \n",
    "    scv.pp.filter_and_normalize(obj, min_shared_counts=10, n_top_genes=3000)\n",
    "    median_genes_per_cell = np.median(obj.X.getnnz(axis=1)) # recomputing this per each dataset will introduce inconsistent thrholds\n",
    "    sc.pp.filter_cells(obj, max_genes=2.5*median_genes_per_cell)\n",
    "    obj.obs['sample_batch'] = [name[0] for name in obj.obs_names.str.split(\"-5\")]\n",
    "    print(\"After filtering: \"+str(obj.shape))\n",
    "    scv.pp.moments(obj, n_neighbors=30, n_pcs=15) # n_pcs=30 by default\n",
    "    \n",
    "    # In order to transfer information from Scanpy and adata, I will subset for the intersection of the two in terms of cells\n",
    "    # I will only transfer louvain and X_umap coordinates\n",
    "    obj = obj[obj.obs_names.intersection(Scanpy_obj.obs_names).to_list(),:]\n",
    "    MatchingIndexes = [Scanpy_obj.obs_names.to_list().index(x) for x in obj.obs_names.intersection(Scanpy_obj.obs_names).to_list()]\n",
    "    SampleIDs = Scanpy_obj.obs.iloc[MatchingIndexes,:].loc[:,'SampleID']\n",
    "    LouvainClusters = Scanpy_obj.obs.iloc[MatchingIndexes,:].loc[:,'louvain']\n",
    "    UmapCoordinates = Scanpy_obj.obsm['X_umap'][MatchingIndexes,:]\n",
    "    obj.obs['SampleID'] = [\"d2d\" if ID == \"48hrsd\" else \n",
    "                           \"d14d\" if ID == \"d14d-1\" else\n",
    "                           \"d14d\" if ID == \"d14d-2\" else\n",
    "                           \"d14d\" if ID == \"d14d-3\" else\n",
    "                           ID for ID in SampleIDs]\n",
    "    obj.obs['louvain'] = LouvainClusters\n",
    "    obj.obsm['X_umap'] = UmapCoordinates\n",
    "    \n",
    "    return(obj)\n",
    "\n",
    "def Velocity_Computations(obj, plotTitle, plotGenes=False):\n",
    "    scv.tl.velocity(obj, mode='stochastic', use_raw = False) # , groupby='SampleID' --> if I use this  {ValueError: You need to run `pp.neighbors` first to compute a neighborhood graph.}\n",
    "    if plotGenes:\n",
    "        scv.pl.velocity(obj, var_names=['OTX2', 'GBX2', 'CRABP2', 'DDIT4','SOX10', 'PAX6','DCX', 'FGF17'])\n",
    "    scv.tl.velocity_graph(obj)\n",
    "    scv.tl.velocity_embedding(obj, basis='umap')\n",
    "    scv.pl.velocity_embedding_stream(obj, color=['SampleID', 'louvain'], title = [plotTitle, plotTitle], basis='umap', vkey='velocity', density=1, legend_loc='on data')\n",
    "    \n",
    "    return(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################DAY 012 VELOCITIES#####\n",
    "d012_Velocity = Dataset_loading_and_cleanup(\"d012\")\n",
    "\n",
    "def VelocityWrapper_d012(args):\n",
    "    ScanpyObject = args[0]\n",
    "    plot_title = args[1]\n",
    "    scVelo_obj = d012_Velocity.copy()\n",
    "    scVelo_obj = Velocity_PreProcessing_UMAP_Clustering(scVelo_obj, Scanpy_obj=ScanpyObject)\n",
    "    scVelo_obj = Velocity_Computations(scVelo_obj, plotTitle = plot_title)\n",
    "    return(scVelo_obj)\n",
    "\n",
    "VelocityArguments_d012 = [\n",
    "                     (d012_list[i], \"Day 0,1,2, MNN, IndPhase\"),\n",
    "                     \n",
    "]\n",
    "VelocityResults_d012 = [*map(VelocityWrapper_d012, VelocityArguments_d012)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Velocity_Computations(obj, plotTitle, plotGenes=False):\n",
    "    obj.obs[\"custom_color\"] = [\"darkgrey\" for i in range(obj.obs.shape[0])]\n",
    "    scv.tl.velocity(obj, mode='stochastic', use_raw = False) # , groupby='SampleID' --> if I use this  {ValueError: You need to run `pp.neighbors` first to compute a neighborhood graph.}\n",
    "    if plotGenes:\n",
    "        scv.pl.velocity(obj, var_names=['OTX2', 'GBX2', 'CRABP2', 'DDIT4','SOX10', 'PAX6','DCX', 'FGF17'])\n",
    "        sc.pl.umap(obj, color = ['SampleID', 'OTX2', 'GBX2', 'PAX6', 'FGF17','DCX', 'phase'], \n",
    "               title = [PlotTitleList_d14[i], 'OTX2', 'GBX2', 'PAX6', 'FGF17','DCX', 'phase'], \n",
    "               legend_loc = 'right margin', use_raw = False, ncols=2, palette='BrBG')\n",
    "    scv.tl.velocity_graph(obj)\n",
    "    scv.tl.velocity_embedding(obj, basis='umap')\n",
    "    #scv.pl.velocity_embedding_stream(obj, color=['SampleID', 'louvain'], title = [plotTitle, plotTitle], basis='umap', vkey='velocity', density=1, legend_loc='right margin',save=\"d012velocity.png\")\n",
    "    scv.pl.velocity_embedding_stream(obj, color=\"custom_color\", title = [plotTitle, plotTitle], basis='umap', vkey='velocity', density=1, legend_loc='right margin',save=\"d012velocity.png\")\n",
    "    #scv.pl.velocity_embedding(obj, color=['SampleID', 'louvain'], title = [plotTitle, plotTitle],basis='umap', arrow_length=2, arrow_size=1.5)\n",
    "    scv.pl.velocity_embedding(obj, title = [plotTitle, plotTitle],basis='umap', arrow_length=2, arrow_size=1.5)\n",
    "    sc.pl.umap(obj, color = ['SampleID', 'OTX2', 'GBX2', 'PAX6', 'FGF17','DCX', 'phase'], \n",
    "               legend_loc = 'right margin', use_raw = False, ncols=2, palette='BrBG')\n",
    "    return(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############DAY 14 VELOCITIES############\n",
    "d14_Velocity = Dataset_loading_and_cleanup(\"d14\")\n",
    "\n",
    "def VelocityWrapper_d14(args):\n",
    "    ScanpyObject = args[0]\n",
    "    plot_title = args[1]\n",
    "    scVelo_obj = d14_Velocity.copy()\n",
    "    scVelo_obj = Velocity_PreProcessing_UMAP_Clustering(scVelo_obj, Scanpy_obj=ScanpyObject)\n",
    "    scVelo_obj = Velocity_Computations(scVelo_obj, plotTitle = plot_title)\n",
    "    return(scVelo_obj)\n",
    "\n",
    "VelocityArguments_d14 = [#(d14_list[0], \"Day 14, BBKNN\"),\n",
    "                     #(d14_list[1], \"Day 14, MNN\"),\n",
    "                     #(d14_list[2], \"Day 14, BBKNN, IndPhase\"),\n",
    "                     (d14_list[i], \"Day 14, MNN, IndPhase\"),\n",
    "                     #(d14_list[4], \"Day 14, BBKNN, PhaseDiff\"),\n",
    "                     #(d14_list[5], \"Day 14, MNN, PhaseDiff\")]\n",
    "]\n",
    "VelocityResults_d14 = [*map(VelocityWrapper_d14, VelocityArguments_d14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gau]",
   "language": "python",
   "name": "conda-env-gau-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
